{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock value prediction from Open, High, Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt2\n",
    "import pandas as pd\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import math, time\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "import pandas_datareader.data as web\n",
    "import h5py\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = '^GSPC'\n",
    "seq_len = 22\n",
    "d = 0.2\n",
    "shape = [4, seq_len, 1] # feature, window, output\n",
    "neurons = [128, 128, 32, 1]\n",
    "epochs = 10000\n",
    "\n",
    "start = datetime.datetime(2013, 1, 1)\n",
    "end = datetime.date.today()\n",
    "neurons_layer = 1\n",
    "optimizer = 'Adam'\n",
    "# loss = 'mse'\n",
    "loss = 'risk_estimation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_estimation(y_true, y_pred):\n",
    "    error_predict_index = y_true * y_pred <= 0\n",
    "    err = y_true - y_pred\n",
    "    err[error_predict_index] *= err[error_predict_index]\n",
    "    \n",
    "    return K.mean(err)\n",
    "\n",
    "get_custom_objects().update({'risk_estimation': risk_estimation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Download data and normalize it\n",
    "Data since date 'start' to today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "   var1(t-3)  var1(t-2)  var1(t-1)  var1(t)\n",
      "3        0.0        1.0        2.0        3\n",
      "4        1.0        2.0        3.0        4\n",
      "5        2.0        3.0        4.0        5\n",
      "6        3.0        4.0        5.0        6\n",
      "7        4.0        5.0        6.0        7\n",
      "8        5.0        6.0        7.0        8\n",
      "9        6.0        7.0        8.0        9\n"
     ]
    }
   ],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "  \"\"\"\n",
    "  函数用途：将时间序列转化为监督学习数据集。\n",
    "  参数说明：\n",
    "    data: 观察值序列，数据类型可以是 list 或者 NumPy array。\n",
    "    n_in: 作为输入值(X)的滞后组的数量。\n",
    "    n_out: 作为输出值(y)的观察组的数量。\n",
    "    dropnan: Boolean 值，确定是否将包含 NaN 的行移除。\n",
    "  返回值:\n",
    "    经过转换的用于监督学习的 Pandas DataFrame 序列。\n",
    "  \"\"\"\n",
    "  n_vars = 1 if type(data) is list else data.shape[1]\n",
    "  df = DataFrame(data)\n",
    "  cols, names = list(), list()\n",
    "  # 输入序列 (t-n, ... t-1)\n",
    "  for i in range(n_in, 0, -1):\n",
    "    cols.append(df.shift(i))\n",
    "    names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "  # 预测序列 (t, t+1, ... t+n)\n",
    "  for i in range(0, n_out):\n",
    "    cols.append(df.shift(-i))\n",
    "    if i == 0:\n",
    "      names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "    else:\n",
    "      names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "  # 将所有列拼合\n",
    "  agg = concat(cols, axis=1)\n",
    "  agg.columns = names\n",
    "  # drop 掉包含 NaN 的行\n",
    "  if dropnan:\n",
    "    agg.dropna(inplace=True)\n",
    "  return agg\n",
    "\n",
    "raw = DataFrame()\n",
    "raw['ob1'] = [x for x in range(10)]\n",
    "# raw['ob2'] = [x for x in range(50, 60)]\n",
    "values = raw.values\n",
    "print(values)\n",
    "data = series_to_supervised(values, 3, 1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name, normalize=True, use_exist_data=True):\n",
    "    \n",
    "    data_path = 'data/' + stock_name\n",
    "    \n",
    "    if use_exist_data and os.path.exists('data/' + stock_name):\n",
    "        df = pd.read_csv(os.path.join(data_path))\n",
    "        print ('read from local')\n",
    "    else:\n",
    "        df = web.DataReader(stock_name, \"yahoo\", start, end)\n",
    "        df.to_csv(data_path)\n",
    "        print ('read from remote')\n",
    "    \n",
    "    df.drop(['Volume', 'Close', 'Date'], 1, inplace=True)\n",
    "    \n",
    "    if normalize:\n",
    "#         yesterday_value = pd.concat([df[:1], df[:len(df)-1]], ignore_index=True)\n",
    "#         df = pd.concat([df[:]], istartgnore_index=True)\n",
    "#         df = df / yesterday_value\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        for feature in df.columns:\n",
    "            df[feature] = min_max_scaler.fit_transform(df[feature].values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from local\n"
     ]
    }
   ],
   "source": [
    "df = get_stock_data(stock_name, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plot out the Normalized Adjusted close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock(stock_name):\n",
    "    df = get_stock_data(stock_name, normalize=True)\n",
    "    print(df.head())\n",
    "    plt.plot(df['Adj Close'], color='red', label='Adj Close')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read from local\n",
      "       Open      High       Low  Adj Close\n",
      "0  0.000000  0.000000  0.000000   0.000000\n",
      "1  0.018415  0.028142  0.021804   0.028664\n",
      "2  0.046494  0.030539  0.044587   0.026251\n",
      "3  0.044130  0.032486  0.047274   0.031868\n",
      "4  0.049633  0.031327  0.045434   0.028244\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAw+OxFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a0b04e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stock(stock_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Set last day Adjusted Close as y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    data = stock.as_matrix() \n",
    "    sequence_length = seq_len + 1 # index starting from 0\n",
    "    result = []\n",
    "    \n",
    "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
    "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
    "    \n",
    "    result = np.array(result)\n",
    "    row = round(0.9 * result.shape[0]) # 90% split\n",
    "    \n",
    "    train = result[:int(row), :] # 90% date\n",
    "    X_train = train[:, :-1] # all data until day m\n",
    "    y_train = train[:, -1][:,-1] # day m + 1 adjusted close price\n",
    "    \n",
    "    X_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1][:,-1] \n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))  \n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(df, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1112, 22, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0], X_train.shape[1], X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Buidling neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(layers, neurons, d):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for i in range(neurons_layer):\n",
    "        model.add(LSTM(neurons[0], input_shape=(layers[1], layers[0]), return_sequences=True))\n",
    "        model.add(Dropout(d))\n",
    "            \n",
    "    model.add(LSTM(neurons[1], input_shape=(layers[1], layers[0]), return_sequences=False))\n",
    "    model.add(Dropout(d))\n",
    "        \n",
    "    model.add(Dense(neurons[2],kernel_initializer=\"uniform\",activation='Tanh'))        \n",
    "    # model.add(Dense(neurons[3],kernel_initializer=\"uniform\",activation='linear'))\n",
    "    # model = load_model('my_LSTM_stock_model1000.h5')\n",
    "    # adam = keras.optimizers.Adam(decay=0.2)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = build_model2(shape, neurons, d)\n",
    "# # layers = [4, 22, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     batch_size=512,\n",
    "#     epochs=epochs,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Result on training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_score(model, X_train, y_train, X_test, y_test):\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    return trainScore[0], testScore[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_score(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Prediction vs Real results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_difference(model, X_test, y_test):\n",
    "    percentage_diff=[]\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    for u in range(len(y_test)): # for each data index in test data\n",
    "        pr = p[u][0] # pr = prediction on day u\n",
    "\n",
    "        percentage_diff.append((pr-y_test[u]/pr)*100)\n",
    "    return percentage_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = percentage_difference(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot out prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(stock_name, normalized_value):\n",
    "    start = datetime.datetime(2000, 1, 1)\n",
    "    end = datetime.date.today()\n",
    "    \n",
    "    df = get_stock_data(stock_name, normalize=False)\n",
    "    df = df['Adj Close'].values.reshape(-1,1)\n",
    "    normalized_value = normalized_value.reshape(-1,1)\n",
    "    \n",
    "    #return df.shape, p.shape\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    a = min_max_scaler.fit_transform(df)\n",
    "    new = min_max_scaler.inverse_transform(normalized_value)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value(stock_name, predict, actual, dir_name, file_name):\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    \n",
    "    fig_path = dir_name + '/' + file_name\n",
    "    \n",
    "    plt2.plot(predict, color='red', label='Prediction')\n",
    "    plt2.plot(actual,color='blue', label='Actual')\n",
    "    plt2.legend(loc='best')\n",
    "    plt2.title('The test result for {}'.format(stock_name))\n",
    "    plt2.xlabel('Days')\n",
    "    plt2.ylabel('Adjusted Close')\n",
    "    plt2.savefig(fig_path, format='png', bbox_inches='tight', transparent=True)\n",
    "    plt2.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(stock_name, normalized_value_p, normalized_value_y_test, epochs, date):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)    \n",
    "    subdir = '/' +  date.strftime(\"%Y%m%d%H%M%S\") + '/' + 'price' \n",
    "    dir_name = str(neurons_layer) + 'layer_' + optimizer + stock_name + '_' + start.strftime(\"%Y%m%d\") + '-' + end.strftime(\"%Y%m%d\") + subdir \n",
    "    figname = stock_name + '_epochs' + str(epochs) + '.png'\n",
    "    plot_value(stock_name, newp, newy_test, dir_name, figname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_result(stock_name, p, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損益計算\n",
    "def plot_value_change_and_revenue(stock_name, normalized_value_p, normalized_value_y_test, epochs, date):\n",
    "    newp = denormalize(stock_name, normalized_value_p)\n",
    "    newy_test = denormalize(stock_name, normalized_value_y_test)\n",
    "    \n",
    "    volumn_change_p = []\n",
    "    volumn_change_y_test = []\n",
    "    revenue_p = []\n",
    "    revenue_y_test = []\n",
    "    total_revenue_p = []\n",
    "    total_revenue_y_test = []\n",
    "    for i in range(len(newp)):\n",
    "        if i == 0:\n",
    "            volumn_change_p.append(0)\n",
    "            volumn_change_y_test.append(0)\n",
    "            \n",
    "            revenue_p.append(0)\n",
    "            revenue_y_test.append(0)\n",
    "            \n",
    "            total_revenue_p.append(0)\n",
    "            total_revenue_y_test.append(0)\n",
    "        else:\n",
    "            volumn_change_p.append(newp[i] - newp[i-1])\n",
    "            volumn_change_y_test.append(newy_test[i] - newy_test[i-1])\n",
    "\n",
    "            if volumn_change_p[i] > volumn_change_p[i-1]:\n",
    "                revenue_p.append(volumn_change_y_test[i] - volumn_change_y_test[i - 1])\n",
    "            else:\n",
    "                revenue_p.append(volumn_change_y_test[i - 1] - volumn_change_y_test[i])\n",
    "            \n",
    "            test_earn = abs(volumn_change_y_test[i] - volumn_change_y_test[i - 1])\n",
    "            revenue_y_test.append(test_earn)\n",
    "            \n",
    "            total_revenue_p.append(total_revenue_p[i - 1] + revenue_p[i])\n",
    "            total_revenue_y_test.append(total_revenue_y_test[i - 1] + revenue_y_test[i])\n",
    "            \n",
    "    figname = stock_name + '_epochs' + str(epochs) + '.png'\n",
    "    \n",
    "    subdir = '/' +  date.strftime(\"%Y%m%d%H%M%S\") + '/' + 'value_change' \n",
    "    dir_name = str(neurons_layer) + 'layer_' + optimizer + stock_name + '_' + start.strftime(\"%Y%m%d\") + '-' + end.strftime(\"%Y%m%d\") + subdir\n",
    "    plot_value(stock_name, volumn_change_p, volumn_change_y_test, dir_name, figname)\n",
    "    \n",
    "    subdir = '/' +  date.strftime(\"%Y%m%d%H%M%S\") + '/' + 'revenue' \n",
    "    dir_name = str(neurons_layer) + 'layer_' + optimizer + stock_name + '_' + start.strftime(\"%Y%m%d\") + '-' + end.strftime(\"%Y%m%d\") + subdir\n",
    "    plot_value(stock_name, revenue_p, revenue_y_test, dir_name, figname)\n",
    "    \n",
    "    subdir = '/' +  date.strftime(\"%Y%m%d%H%M%S\") + '/' + 'revenue_sum' \n",
    "    dir_name = str(neurons_layer) + 'layer_' + optimizer + stock_name + '_' + start.strftime(\"%Y%m%d\") + '-' + end.strftime(\"%Y%m%d\") + subdir\n",
    "    plot_value(stock_name, total_revenue_p, total_revenue_y_test, dir_name, figname)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Save for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 22, 128)           68096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 22, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 203,841\n",
      "Trainable params: 203,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1000 samples, validate on 112 samples\n",
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.1896 - acc: 0.0000e+00 - val_loss: 0.5345 - val_acc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 1s 987us/step - loss: 0.1776 - acc: 0.0000e+00 - val_loss: 0.4820 - val_acc: 0.0000e+00\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1535 - acc: 0.0000e+00 - val_loss: 0.3700 - val_acc: 0.0000e+00\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.1009 - acc: 0.0000e+00 - val_loss: 0.2037 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0701 - val_acc: 0.0000e+00\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Epoch 7/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 8/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0745 - val_acc: 0.0000e+00\n",
      "Epoch 9/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.1213 - val_acc: 0.0000e+00\n",
      "Epoch 10/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.1504 - val_acc: 0.0000e+00\n",
      "Epoch 11/25\n",
      "1000/1000 [==============================] - 1s 996us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.1569 - val_acc: 0.0000e+00\n",
      "Epoch 12/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.1466 - val_acc: 0.0000e+00\n",
      "Epoch 13/25\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.1283 - val_acc: 0.0000e+00\n",
      "Epoch 14/25\n",
      " 512/1000 [==============>...............] - ETA: 0s - loss: 0.0181 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d7cd3c97c10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_plot_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         verbose=1)\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplot_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_plot_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_date = datetime.datetime.now()\n",
    "save_plot_epochs = 25\n",
    "\n",
    "model = build_model2(shape, neurons, d)\n",
    "for i in range(int(epochs / save_plot_epochs)):\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=512,\n",
    "        epochs=save_plot_epochs,\n",
    "        validation_split=0.1,\n",
    "        verbose=1)\n",
    "    predict_y = model.predict(X_test)\n",
    "    plot_result(stock_name, predict_y, y_test, save_plot_epochs * (i + 1), run_date)\n",
    "    plot_value_change_and_revenue(stock_name, predict_y, y_test, save_plot_epochs * (i + 1), run_date)\n",
    "# model.save('LSTM_Stock_prediction-20170429.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
